{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-08-15T23:09:49.205819Z",
     "iopub.status.busy": "2025-08-15T23:09:49.205264Z",
     "iopub.status.idle": "2025-08-15T23:10:25.143743Z",
     "shell.execute_reply": "2025-08-15T23:10:25.139223Z",
     "shell.execute_reply.started": "2025-08-15T23:09:49.205791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jax[tpu] in /usr/local/lib/python3.10/site-packages (0.4.34)\n",
      "Collecting jax[tpu]\n",
      "  Downloading jax-0.6.2-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml_dtypes>=0.5.0\n",
      "  Downloading ml_dtypes-0.5.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.10/site-packages (from jax[tpu]) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.10/site-packages (from jax[tpu]) (1.15.3)\n",
      "Collecting jaxlib<=0.6.2,>=0.6.2\n",
      "  Downloading jaxlib-0.6.2-cp310-cp310-manylinux2014_x86_64.whl (89.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt_einsum in /usr/local/lib/python3.10/site-packages (from jax[tpu]) (3.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from jax[tpu]) (2.32.4)\n",
      "Collecting libtpu==0.0.17.*\n",
      "  Downloading libtpu-0.0.17-py3-none-manylinux_2_31_x86_64.whl (135.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.2/135.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->jax[tpu]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->jax[tpu]) (2025.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->jax[tpu]) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->jax[tpu]) (3.4.2)\n",
      "Installing collected packages: libtpu, ml_dtypes, jaxlib, jax\n",
      "  Attempting uninstall: libtpu\n",
      "    Found existing installation: libtpu 2.18.0\n",
      "    Uninstalling libtpu-2.18.0:\n",
      "      Successfully uninstalled libtpu-2.18.0\n",
      "  Attempting uninstall: ml_dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: jaxlib\n",
      "    Found existing installation: jaxlib 0.4.34\n",
      "    Uninstalling jaxlib-0.4.34:\n",
      "      Successfully uninstalled jaxlib-0.4.34\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.4.34\n",
      "    Uninstalling jax-0.4.34:\n",
      "      Successfully uninstalled jax-0.4.34\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-tpu 2.18.0 requires libtpu==2.18.0, but you have libtpu 0.0.17 which is incompatible.\n",
      "tensorflow-tpu 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jax-0.6.2 jaxlib-0.6.2 libtpu-0.0.17 ml_dtypes-0.5.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: flax in /usr/local/lib/python3.10/site-packages (0.10.4)\n",
      "Collecting flax\n",
      "  Downloading flax-0.10.7-py3-none-any.whl (456 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.9/456.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jaxlib in /usr/local/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: optax in /usr/local/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/site-packages (from flax) (6.0.2)\n",
      "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/site-packages (from flax) (0.11.5)\n",
      "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.10/site-packages (from flax) (4.14.0)\n",
      "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.10/site-packages (from flax) (0.1.9)\n",
      "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/site-packages (from flax) (0.1.74)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/site-packages (from flax) (1.1.1)\n",
      "Requirement already satisfied: jax>=0.6.0 in /usr/local/lib/python3.10/site-packages (from flax) (0.6.2)\n",
      "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/site-packages (from flax) (14.0.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.10/site-packages (from jaxlib) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.10/site-packages (from jaxlib) (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.10/site-packages (from jaxlib) (2.0.2)\n",
      "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/site-packages (from optax) (0.1.89)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/site-packages (from optax) (2.3.0)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/site-packages (from chex>=0.1.87->optax) (1.0.0)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.10/site-packages (from jax>=0.6.0->flax) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=11.1->flax) (2.19.2)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.10/site-packages (from orbax-checkpoint->flax) (4.12.3)\n",
      "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/site-packages (from orbax-checkpoint->flax) (1.12.2)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.10/site-packages (from orbax-checkpoint->flax) (3.20.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/site-packages (from orbax-checkpoint->flax) (5.29.5)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.5.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2025.5.1)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.23.0)\n",
      "Installing collected packages: flax\n",
      "  Attempting uninstall: flax\n",
      "    Found existing installation: flax 0.10.4\n",
      "    Uninstalling flax-0.10.4:\n",
      "      Successfully uninstalled flax-0.10.4\n",
      "Successfully installed flax-0.10.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"jax[tpu]\"\n",
    "!pip install --upgrade flax jaxlib optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:10:25.147111Z",
     "iopub.status.busy": "2025-08-15T23:10:25.145901Z",
     "iopub.status.idle": "2025-08-15T23:11:15.107220Z",
     "shell.execute_reply": "2025-08-15T23:11:15.101406Z",
     "shell.execute_reply.started": "2025-08-15T23:10:25.147085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#~ machine learning libraries\n",
    "import jax\n",
    "import flax\n",
    "import optax\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "from flax.training.train_state import TrainState\n",
    "from transformers import AutoTokenizer, FlaxAutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "#~ base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#~ auxiliary libraries\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the hyperparameters. You can change them depending on your preference.\n",
    "\n",
    "`model_name` can be changed to:\n",
    "- `bert-large-uncased`\n",
    "- `bert-base-uncased`\n",
    "\n",
    "`seed` can be changed to any integer. It simply defines the starting point of all random number generators (from now on we'll call them RNGs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:15.109279Z",
     "iopub.status.busy": "2025-08-15T23:11:15.108906Z",
     "iopub.status.idle": "2025-08-15T23:11:15.117510Z",
     "shell.execute_reply": "2025-08-15T23:11:15.112965Z",
     "shell.execute_reply.started": "2025-08-15T23:11:15.109255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-large-uncased\"\n",
    "seed = 129"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if JAX sees the accelerator we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:15.118342Z",
     "iopub.status.busy": "2025-08-15T23:11:15.118143Z",
     "iopub.status.idle": "2025-08-15T23:11:20.807922Z",
     "shell.execute_reply": "2025-08-15T23:11:20.802723Z",
     "shell.execute_reply.started": "2025-08-15T23:11:15.118322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1755299476.780432      10 common_lib.cc:648] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: ===\n",
      "learning/45eac/tfrc/runtime/common_lib.cc:238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpu\n",
      "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n"
     ]
    }
   ],
   "source": [
    "print(jax.default_backend())\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the accelerator's name printed out in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:20.809062Z",
     "iopub.status.busy": "2025-08-15T23:11:20.808809Z",
     "iopub.status.idle": "2025-08-15T23:11:20.822593Z",
     "shell.execute_reply": "2025-08-15T23:11:20.816382Z",
     "shell.execute_reply.started": "2025-08-15T23:11:20.809038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating variables for data directories isn't necessary, but I tend to think it's good practise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:20.825036Z",
     "iopub.status.busy": "2025-08-15T23:11:20.824765Z",
     "iopub.status.idle": "2025-08-15T23:11:20.834998Z",
     "shell.execute_reply": "2025-08-15T23:11:20.830459Z",
     "shell.execute_reply.started": "2025-08-15T23:11:20.825011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_dir = \"/kaggle/input/nlp-getting-started/\"\n",
    "train_dir = base_dir + \"train.csv\"\n",
    "test_dir = base_dir + \"test.csv\"\n",
    "sample_submission_dir = base_dir + \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:20.837241Z",
     "iopub.status.busy": "2025-08-15T23:11:20.837043Z",
     "iopub.status.idle": "2025-08-15T23:11:20.920347Z",
     "shell.execute_reply": "2025-08-15T23:11:20.915449Z",
     "shell.execute_reply.started": "2025-08-15T23:11:20.837222Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>4556</td>\n",
       "      <td>emergency%20plan</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>http://t.co/F7LJwxJ5jp #GamerGate The end of R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>6583</td>\n",
       "      <td>injury</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>Ngata on injury list at start of practice for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>5083</td>\n",
       "      <td>famine</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Russia destroys food while people go hungry.  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>3485</td>\n",
       "      <td>derailed</td>\n",
       "      <td>SEC Country</td>\n",
       "      <td>@BobbyofHomewood @JOXRoundtable as in dropping...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>9342</td>\n",
       "      <td>survived</td>\n",
       "      <td>London</td>\n",
       "      <td>Survived another tube strike with the last per...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           keyword       location  \\\n",
       "3174  4556  emergency%20plan         Reddit   \n",
       "4632  6583            injury      Baltimore   \n",
       "3557  5083            famine  Massachusetts   \n",
       "2425  3485          derailed    SEC Country   \n",
       "6531  9342          survived         London   \n",
       "\n",
       "                                                   text  target  \n",
       "3174  http://t.co/F7LJwxJ5jp #GamerGate The end of R...       0  \n",
       "4632  Ngata on injury list at start of practice for ...       0  \n",
       "3557  Russia destroys food while people go hungry.  ...       1  \n",
       "2425  @BobbyofHomewood @JOXRoundtable as in dropping...       0  \n",
       "6531  Survived another tube strike with the last per...       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe = pd.read_csv(train_dir)\n",
    "test_dataframe = pd.read_csv(test_dir)\n",
    "\n",
    "train_dataframe.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:20.922556Z",
     "iopub.status.busy": "2025-08-15T23:11:20.922314Z",
     "iopub.status.idle": "2025-08-15T23:11:22.959019Z",
     "shell.execute_reply": "2025-08-15T23:11:22.954653Z",
     "shell.execute_reply.started": "2025-08-15T23:11:20.922535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the models can't take batches of data with arrays that have different lengths. Because of that we'll have to pad all the sentences to the maximum length (i. e. to the length of the longest encoded sentence). And yes, we'll have to look through both training and testing data. It isn't that hard though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:22.961074Z",
     "iopub.status.busy": "2025-08-15T23:11:22.960859Z",
     "iopub.status.idle": "2025-08-15T23:11:24.414648Z",
     "shell.execute_reply": "2025-08-15T23:11:24.409127Z",
     "shell.execute_reply.started": "2025-08-15T23:11:22.961053Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length: 84 IDs\n"
     ]
    }
   ],
   "source": [
    "max_sentence_length = 0\n",
    "\n",
    "combined_dataframe = pd.concat([train_dataframe, test_dataframe])\n",
    "\n",
    "for sentence in combined_dataframe.text:\n",
    "    encoded_sentence = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    max_sentence_length = max(len(encoded_sentence), max_sentence_length)\n",
    "\n",
    "print(f\"Maximum sentence length: {max_sentence_length} IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main encoding part is slightly more difficult. We'll have to define three arrays for input IDs, token type IDs and attention masks respectively. Then, after encoding each sentence, we'll add the encoded data to their respective arrays. Output of the function is a dictionary containing the following entries:\n",
    "- `input_ids`\n",
    "- `token_type_ids`\n",
    "- `attention_mask`\n",
    "- `labels` (**only if labels were specified!** that'll help us get them faster in the training step function)\n",
    "\n",
    "The `IntegerMatrix` variable defines the type of our arrays, since they're gonna contain lists of lists, each of the same length and with integer values inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:24.417576Z",
     "iopub.status.busy": "2025-08-15T23:11:24.417302Z",
     "iopub.status.idle": "2025-08-15T23:11:24.428782Z",
     "shell.execute_reply": "2025-08-15T23:11:24.425207Z",
     "shell.execute_reply.started": "2025-08-15T23:11:24.417540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IntegerMatrix = list[list[int]]\n",
    "\n",
    "def preprocess_dataframe(data: pd.Series, labels: pd.Series | None = None):\n",
    "    input_ids: IntegerMatrix = []\n",
    "    token_type_ids: IntegerMatrix = []\n",
    "    attention_masks: IntegerMatrix = []\n",
    "        \n",
    "    for sentence in data:\n",
    "        tokenizer_output: dict[str, list[int]] = tokenizer(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_sentence_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        input_ids.append(tokenizer_output[\"input_ids\"])\n",
    "        token_type_ids.append(tokenizer_output[\"token_type_ids\"])\n",
    "        attention_masks.append(tokenizer_output[\"attention_mask\"])\n",
    "\n",
    "    input_ids = torch.cat(input_ids)\n",
    "    token_type_ids = torch.cat(token_type_ids)\n",
    "    attention_masks = torch.cat(attention_masks)\n",
    "    \n",
    "    if labels is not None:\n",
    "        labels = torch.from_numpy(labels.to_numpy()).to(torch.float32)\n",
    "        return input_ids, token_type_ids, attention_masks, labels\n",
    "    else:\n",
    "        return input_ids, token_type_ids, attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function isn't difficult. For the train data, pass the data and the labels (`text` and `target` columns of the dataframe). For the test data, pass only the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:24.432265Z",
     "iopub.status.busy": "2025-08-15T23:11:24.432027Z",
     "iopub.status.idle": "2025-08-15T23:11:27.515257Z",
     "shell.execute_reply": "2025-08-15T23:11:27.510796Z",
     "shell.execute_reply.started": "2025-08-15T23:11:24.432242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labeled_data = preprocess_dataframe(\n",
    "    train_dataframe.text,\n",
    "    train_dataframe.target)\n",
    "\n",
    "test_data = preprocess_dataframe(test_dataframe.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:27.517668Z",
     "iopub.status.busy": "2025-08-15T23:11:27.517400Z",
     "iopub.status.idle": "2025-08-15T23:11:27.536249Z",
     "shell.execute_reply": "2025-08-15T23:11:27.531443Z",
     "shell.execute_reply.started": "2025-08-15T23:11:27.517646Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  2256, 15616,  ...,     0,     0,     0],\n",
       "         [  101,  3224,  2543,  ...,     0,     0,     0],\n",
       "         [  101,  2035,  3901,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101, 23290,  1012,  ...,     0,     0,     0],\n",
       "         [  101,  2610, 11538,  ...,     0,     0,     0],\n",
       "         [  101,  1996,  6745,  ...,     0,     0,     0]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([1., 1., 1.,  ..., 1., 1., 1.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `torch` library has a lot of data loading pipelines to utilize. One of the useful ones is `TensorDataset` - it allows you to pass any number of tensors, which will be used to create the dataset.\n",
    "\n",
    "`labeled_dataset` will be split into training and validation datasets, hence it's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:27.538542Z",
     "iopub.status.busy": "2025-08-15T23:11:27.538300Z",
     "iopub.status.idle": "2025-08-15T23:11:27.553551Z",
     "shell.execute_reply": "2025-08-15T23:11:27.549071Z",
     "shell.execute_reply.started": "2025-08-15T23:11:27.538520Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  2256, 15616,  2024,  1996,  3114,  1997,  2023,  1001,  8372,\n",
       "          2089, 16455,  9641,  2149,  2035,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_dataset = TensorDataset(*labeled_data)\n",
    "test_dataset = TensorDataset(*test_data)\n",
    "\n",
    "next(iter(labeled_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there's yet another useful module! `random_split` allows you to split a PyTorch dataset (like the one we've created above) into an arbitrary amount of new datasets with the corresponding sizes specified in the following argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:27.555311Z",
     "iopub.status.busy": "2025-08-15T23:11:27.555072Z",
     "iopub.status.idle": "2025-08-15T23:11:27.570613Z",
     "shell.execute_reply": "2025-08-15T23:11:27.566750Z",
     "shell.execute_reply.started": "2025-08-15T23:11:27.555289Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  1030,  7158, 10760, 16715,  4364,  2000,  6015,  2000,  2265,\n",
       "          2010,  2613,  2171,  4312,  2002,  4282,  1045,  1005,  2222,  5968,\n",
       "          2032,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining dataset sizes\n",
    "train_dataset_size = int(0.8 * len(labeled_dataset))\n",
    "validation_dataset_size = len(labeled_dataset) - train_dataset_size\n",
    "\n",
    "# splitting the datasets\n",
    "# random_split(<dataset>, [<sizes>])\n",
    "# the number of variables you're assigning the output of random_split to must be equal to the number of sizes you've specified\n",
    "train_dataset, validation_dataset = random_split(labeled_dataset, [train_dataset_size, validation_dataset_size])\n",
    "\n",
    "# checking the output of the dataset\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of that data preprocessing leads us here - creating `DataLoader`s is the last step. `DataLoader` is PyTorch's most utilized data-loading pipeline. It can batch data, shuffle it after every epoch, apply any passed function onto every batch and so on!\n",
    "\n",
    "Samplers are also an interesting concept. They define how the data is fetched. `RandomSampler` picks batches at random, `SequentialSampler` sequentially fetches the batches, one after another. Those are the main ones we'll use.\n",
    "\n",
    "Their usage is simple - you pass the same dataset you'll use in the dataloader. The sampler must be specified by it's keyword in the dataloader class, much like any non-dataset parameter.\n",
    "\n",
    "We'll need the data in the output batches converted to JAX arrays, since that's the only array variant that JAX's JIT (Just-In-Time) compilation allows to be passed. More on JIT later ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:27.573238Z",
     "iopub.status.busy": "2025-08-15T23:11:27.572720Z",
     "iopub.status.idle": "2025-08-15T23:11:27.583193Z",
     "shell.execute_reply": "2025-08-15T23:11:27.579040Z",
     "shell.execute_reply.started": "2025-08-15T23:11:27.573217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def labeled_collate_fn(unprocessed_batch):\n",
    "    input_ids, token_type_ids, attention_masks, labels = zip(*unprocessed_batch)\n",
    "\n",
    "    return (\n",
    "        jnp.array(input_ids),\n",
    "        jnp.array(token_type_ids),\n",
    "        jnp.array(attention_masks),\n",
    "        jnp.array(labels, dtype=jnp.int32)\n",
    "    )\n",
    "\n",
    "def unlabeled_collate_fn(unprocessed_batch):\n",
    "    input_ids, token_type_ids, attention_masks, = zip(*unprocessed_batch)\n",
    "\n",
    "    return (\n",
    "        jnp.array(input_ids),\n",
    "        jnp.array(token_type_ids),\n",
    "        jnp.array(attention_masks)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:27.585556Z",
     "iopub.status.busy": "2025-08-15T23:11:27.585313Z",
     "iopub.status.idle": "2025-08-15T23:11:27.889344Z",
     "shell.execute_reply": "2025-08-15T23:11:27.883810Z",
     "shell.execute_reply.started": "2025-08-15T23:11:27.585533Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[  101,  1005,  2017, ...,     0,     0,     0],\n",
       "        [  101,  3748,  8769, ...,     0,     0,     0],\n",
       "        [  101,  8299,  1024, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1996,  5072, ...,     0,     0,     0],\n",
       "        [  101,  1030, 13434, ...,     0,     0,     0],\n",
       "        [  101,  6040,  2013, ...,     0,     0,     0]], dtype=int32),\n",
       " Array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32),\n",
       " Array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32),\n",
       " Array([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# train dataloader\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=labeled_collate_fn\n",
    ")\n",
    "\n",
    "# validation dataloader\n",
    "validation_sampler = SequentialSampler(validation_dataset)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=validation_sampler,\n",
    "    collate_fn=labeled_collate_fn\n",
    ")\n",
    "\n",
    "# test dataloader\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=test_sampler,\n",
    "    collate_fn=unlabeled_collate_fn\n",
    ")\n",
    "\n",
    "# checking if it works like intended\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning the model\n",
    "This is where we utilize JAX and Flax. Don't expect it to be easy, though I'll try to explain everything in details :)\n",
    "\n",
    "We'll have to prepare:\n",
    "- configurations - parameters that will be automatically specified in the model, such as whether to output attentions and hidden states.\n",
    "- the model - pretrained model from `transformer`'s `FlaxAutoModelForSequenceClassification`. This is where the configurations are passed.\n",
    "- `TrainState` - Flax's useful class for storing all the modules and functions used for training. In our case, it's the model's apply function, parameters (i. e. weights and biases) and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:27.890975Z",
     "iopub.status.busy": "2025-08-15T23:11:27.890020Z",
     "iopub.status.idle": "2025-08-15T23:11:42.782552Z",
     "shell.execute_reply": "2025-08-15T23:11:42.775165Z",
     "shell.execute_reply.started": "2025-08-15T23:11:27.890951Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias'), ('cls', 'predictions', 'bias')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: {('bert', 'pooler', 'dense', 'bias'), ('classifier', 'kernel'), ('bert', 'pooler', 'dense', 'kernel'), ('classifier', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(model_name, config=config, seed=seed)\n",
    "optimizer = optax.adamw(learning_rate=6e-5, eps=1e-8)\n",
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.__call__,\n",
    "    params=model.params,\n",
    "    tx=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the model to output hidden states and attention scores every step. Let's see whether that's gonna happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:42.784489Z",
     "iopub.status.busy": "2025-08-15T23:11:42.784238Z",
     "iopub.status.idle": "2025-08-15T23:11:42.792518Z",
     "shell.execute_reply": "2025-08-15T23:11:42.788374Z",
     "shell.execute_reply.started": "2025-08-15T23:11:42.784466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will output the hidden states: NO\n",
      "Model will output attentions: NO\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model will output the hidden states: {'YES' if config.output_hidden_states else 'NO'}\")\n",
    "print(f\"Model will output attentions: {'YES' if config.output_attentions else 'NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully not.\n",
    "\n",
    "Our training step will look something like this:\n",
    "- Labels will be separated from the main batch.\n",
    "- We'll define the loss function, which fetches the logits from the function and calculates the loss with respect to the labels.\n",
    "- Loss and gradients will be fetched using JAX's `value_and_grad` wrapper.\n",
    "- We'll apply the gradients using the state's `apply_gradients`, giving us a new train state.\n",
    "- To continue the training, we'll return the state and the loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:11:42.795097Z",
     "iopub.status.busy": "2025-08-15T23:11:42.794853Z",
     "iopub.status.idle": "2025-08-15T23:12:00.317202Z",
     "shell.execute_reply": "2025-08-15T23:12:00.312850Z",
     "shell.execute_reply.started": "2025-08-15T23:11:42.795075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(\n",
    "    state: TrainState,\n",
    "    batch: tuple[jax.Array],\n",
    "    dropout_rng: jax.random.PRNGKey\n",
    ") -> tuple[TrainState, jax.Array]:\n",
    "    \n",
    "    batch, labels = batch[:-1], batch[-1]\n",
    "    \n",
    "    def loss_fn(params):\n",
    "        output = state.apply_fn(*batch, params=params, dropout_rng=dropout_rng, train=True)\n",
    "        logits = output.logits\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()\n",
    "        return loss\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "    return state, loss\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(\n",
    "    state: TrainState,\n",
    "    batch: tuple[jax.Array],\n",
    "    dropout_rng: jax.random.PRNGKey\n",
    ") -> jax.Array:\n",
    "    batch, labels = batch[:-1], batch[-1]\n",
    "    \n",
    "    output = state.apply_fn(*batch, params=state.params, dropout_rng=dropout_rng, train=False)\n",
    "    logits = output.logits\n",
    "\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the training loop, we'll pack the single-step functions above in corresponding single-epoch functions defined below. It shouldn't be that hard, considering all we need to do is iterate through the dataloaders, track batch losses and divide their sum by the number of batches in the respective dataloaders (i. e. by the dataloaders' lengths).\n",
    "\n",
    "We don't wrap them with `jax.jit` since they additionally take PyTorch's dataloaders, which can't be traced by JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:12:00.319586Z",
     "iopub.status.busy": "2025-08-15T23:12:00.319330Z",
     "iopub.status.idle": "2025-08-15T23:12:00.353943Z",
     "shell.execute_reply": "2025-08-15T23:12:00.347458Z",
     "shell.execute_reply.started": "2025-08-15T23:12:00.319560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    state: TrainState,\n",
    "    dataloader: DataLoader,\n",
    "    dropout_rng: jax.random.PRNGKey\n",
    ") -> tuple[TrainState, float]:\n",
    "    \n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        dropout_rng, other_dropout_rng = jax.random.split(dropout_rng)\n",
    "        state, loss = train_step(state, batch, dropout_rng)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    return state, average_loss\n",
    "\n",
    "\n",
    "def eval_epoch(\n",
    "    state: TrainState,\n",
    "    dataloader: DataLoader,\n",
    "    dropout_rng: jax.random.PRNGKey\n",
    ") -> float:\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        dropout_rng, other_dropout_rng = jax.random.split(dropout_rng)\n",
    "        loss = eval_step(state, batch, dropout_rng)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might've noticed, our divide-and-conquer strategy works quite well - the training loop is as simple as it gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:12:00.355403Z",
     "iopub.status.busy": "2025-08-15T23:12:00.355171Z",
     "iopub.status.idle": "2025-08-15T23:18:47.567879Z",
     "shell.execute_reply": "2025-08-15T23:18:47.562110Z",
     "shell.execute_reply.started": "2025-08-15T23:12:00.355380Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   Training...\n",
      "   > Train loss: 0.7149\n",
      "\n",
      "   Evaluating...\n",
      "   > Validation loss: 0.6837\n",
      "\n",
      "Epoch 2/3\n",
      "   Training...\n",
      "   > Train loss: 0.7120\n",
      "\n",
      "   Evaluating...\n",
      "   > Validation loss: 0.6853\n",
      "\n",
      "Epoch 3/3\n",
      "   Training...\n",
      "   > Train loss: 0.7039\n",
      "\n",
      "   Evaluating...\n",
      "   > Validation loss: 0.6997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "dropout_rng = jax.random.PRNGKey(seed)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    dropout_rng, other_dropout_rng = jax.random.split(dropout_rng)\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "\n",
    "    print(f\"   Training...\")\n",
    "    state, loss = train_epoch(state, train_dataloader, dropout_rng)\n",
    "    print(f\"   > Train loss: {loss:.4f}\\n\")\n",
    "\n",
    "    print(f\"   Evaluating...\")\n",
    "    loss = eval_epoch(state, validation_dataloader, other_dropout_rng)\n",
    "    print(f\"   > Validation loss: {loss:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "For prediction, we'll use the same strategy for consistency - create a single-step function (prediction on a single batch, wrapped with JIT) and use it in a single-epoch function (prediction on the whole dataloader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:18:47.570441Z",
     "iopub.status.busy": "2025-08-15T23:18:47.570188Z",
     "iopub.status.idle": "2025-08-15T23:18:47.582985Z",
     "shell.execute_reply": "2025-08-15T23:18:47.576954Z",
     "shell.execute_reply.started": "2025-08-15T23:18:47.570404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def predict_on_batch(\n",
    "    state: TrainState,\n",
    "    batch: tuple[jax.Array]\n",
    ") -> jax.Array:\n",
    "    \n",
    "    output = state.apply_fn(*batch, params=state.params, train=False)\n",
    "    predictions = jnp.argmax(output.logits, axis=-1)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def predict_on_dataloader(\n",
    "    state: TrainState,\n",
    "    dataloader: DataLoader\n",
    ") -> list:\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch_predictions = predict_on_batch(state, batch)\n",
    "        predictions.extend(np.array(batch_predictions).tolist())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, would you look at that - predicting takes only a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:18:47.584958Z",
     "iopub.status.busy": "2025-08-15T23:18:47.584692Z",
     "iopub.status.idle": "2025-08-15T23:19:13.830271Z",
     "shell.execute_reply": "2025-08-15T23:19:13.824818Z",
     "shell.execute_reply.started": "2025-08-15T23:18:47.584934Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_on_dataloader(state, test_dataloader)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the sample submission file from the directory we've specified in the beginning. It will be useful to quickly create a submission file for the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:19:13.832955Z",
     "iopub.status.busy": "2025-08-15T23:19:13.832658Z",
     "iopub.status.idle": "2025-08-15T23:19:13.868814Z",
     "shell.execute_reply": "2025-08-15T23:19:13.863086Z",
     "shell.execute_reply.started": "2025-08-15T23:19:13.832931Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>5984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>1993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>7886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>3644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "1771   5984       0\n",
       "3260  10868       0\n",
       "610    1993       0\n",
       "2357   7886       0\n",
       "1104   3644       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(sample_submission_dir)\n",
    "submission.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing you have to do is put the predictions in the `target` column. That's it. Your submission dataframe is ready to be converted.\n",
    "\n",
    "The predictions array should be either a `list`, `tuple` or a `np.ndarray` instance. Those are the only array types pandas allows to use instead as columns. It's a `list` in our case, so we should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:19:13.871039Z",
     "iopub.status.busy": "2025-08-15T23:19:13.870812Z",
     "iopub.status.idle": "2025-08-15T23:19:13.886324Z",
     "shell.execute_reply": "2025-08-15T23:19:13.881856Z",
     "shell.execute_reply.started": "2025-08-15T23:19:13.871019Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>9021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>5786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>3272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>6761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>10602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "2710   9021       0\n",
       "1715   5786       0\n",
       "992    3272       0\n",
       "2008   6761       0\n",
       "3191  10602       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"target\"] = predictions\n",
    "submission.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, the final step - converting the submission dataframe to a CSV file. It's also important to specify `index` as `False`, since otherwise Kaggle won't be able to correctly review your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:19:13.888524Z",
     "iopub.status.busy": "2025-08-15T23:19:13.888308Z",
     "iopub.status.idle": "2025-08-15T23:19:13.907654Z",
     "shell.execute_reply": "2025-08-15T23:19:13.903151Z",
     "shell.execute_reply.started": "2025-08-15T23:19:13.888504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31091,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
